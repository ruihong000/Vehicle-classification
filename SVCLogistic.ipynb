{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "os.chdir(\"D:/research\")\n",
    "\n",
    "more = True\n",
    "use_drive = False\n",
    "use_dev = True\n",
    "use_cluster = True\n",
    "use_sample = True\n",
    "use_temporal= True\n",
    "use_road = True\n",
    "features = pd.read_csv('Device_all_cluster1.csv')\n",
    "features = features.drop(['list'], axis = 1)\n",
    "features.fillna({'HourMax1':'None', 'HourMax2':'None', 'HourMax3':'None', 'HourMax4':'None',\n",
    "                 'CountMax1':0,  'CountMax2':0,  'CountMax3':0, 'CountMax4':0}, inplace=True)\n",
    "\n",
    "features = pd.concat([features,pd.get_dummies(features['GeospatialType'])], axis = 1)\n",
    "\n",
    "features['CountMax1'] = features['CountMax1']/features['TotalNumTrip']\n",
    "features['CountMax2'] = features['CountMax2']/features['TotalNumTrip']\n",
    "features['CountMax3'] = features['CountMax3']/features['TotalNumTrip']\n",
    "features['CountMax4'] = features['CountMax4']/features['TotalNumTrip']\n",
    "\n",
    "\n",
    "features['first_cluster_count'] = features['first_cluster_count']/features['TotalNumTrip']\n",
    "features['second_cluster_count'] = features['second_cluster_count']/features['TotalNumTrip']\n",
    "drop_dev = ['std_average_speed', 'std_detour_metrics', 'std_POInum', 'std_Total_time_interval', 'std_TotalDistance',\n",
    "           'STD Local', 'STD Collector', 'STD Principal Arterial', 'STD Minor Arterial', 'STD None']\n",
    "drop_road = ['Average Local', 'Average Collector', 'Average Principal Arterial',\n",
    "             'Average Minor Arterial','Average None']\n",
    "drop_cluster = ['first_cluster_count', 'second_cluster_count','total_cluster_num']\n",
    "drop_sample = ['mean_AvgTimeGra','mean_AvgDistanceGra','mean_point_num']\n",
    "drop_temporal = ['CountMax1','DistinctHour']\n",
    "drop_drive = ['mean_detour_metrics', 'mean_POInum', 'mean_TotalDistance',\n",
    "       'mean_average_speed', 'mean_Total_time_interval','EE', 'EI', 'IE', 'II']\n",
    "# features = features.drop(drop_names, axis=1)\n",
    "if use_dev == False:\n",
    "    features = features.drop(drop_dev, axis=1)\n",
    "if use_drive == False:\n",
    "    features = features.drop(drop_drive, axis=1)\n",
    "    \n",
    "if use_cluster == False:\n",
    "    features = features.drop(drop_cluster, axis=1)\n",
    "if use_sample == False:\n",
    "    features = features.drop(drop_sample, axis=1)\n",
    "if use_road == False:\n",
    "    features = features.drop(drop_road, axis=1)\n",
    "if use_temporal == True:\n",
    "    features = pd.concat([features,pd.get_dummies(features['HourMax1'])], axis = 1)\n",
    "else:\n",
    "    features = features.drop(drop_temporal, axis=1)\n",
    "features = features.dropna()\n",
    "if use_dev == True:\n",
    "    features = features.dropna(axis = 0)\n",
    "Consumer = features[features['min_profile'] == 1]\n",
    "Taxi = features[features['min_profile'] == 2]\n",
    "Delivery = features[features['min_profile'] == 3]\n",
    "Truck = features[features['min_profile'] == 4]\n",
    "\n",
    "if more == True:\n",
    "    n = min([Consumer.shape[0], Delivery.shape[0], Truck.shape[0]])\n",
    "    \n",
    "    Truck = Truck.sample(n=n, random_state=33)\n",
    "    Consumer = Consumer.sample(n=n, random_state=33)\n",
    "    Delivery = Delivery.sample(n=n, random_state=33)\n",
    "    features = pd.concat([Consumer, Delivery, Truck], axis = 0)\n",
    "    del Consumer, Delivery, Truck\n",
    "    \n",
    "else:\n",
    "    n = Taxi.shape[0]\n",
    "    Truck = Truck.sample(n=n, random_state=3)\n",
    "    Consumer = Consumer.sample(n=n, random_state=23)\n",
    "    Delivery = Delivery.sample(n=n, random_state=57)\n",
    "    features = pd.concat([Consumer, Taxi, Delivery, Truck], axis = 0)\n",
    "    del Consumer, Taxi, Delivery, Truck\n",
    "    \n",
    "labels = np.array(features['min_profile'])\n",
    "features = features.drop(['DeviceId', 'min_profile','max_profile', 'GeospatialType', 'TotalNumTrip', \n",
    "                          'HourMax1',  'std_AvgTimeGra',  'std_AvgDistanceGra', 'std_point_num', \n",
    "                          'HourMax2','HourMax3','HourMax4', 'CountMax2', 'CountMax3', 'CountMax4'], axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=40)\n",
    "    \n",
    "\n",
    "# from sklearn import preprocessing\n",
    "# normalized_features = preprocessing.normalize(features)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(normalized_features, labels, test_size=0.2, random_state=40)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_detour_metrics', 'mean_POInum', 'mean_TotalDistance',\n",
       "       'mean_average_speed', 'mean_Total_time_interval', 'first_cluster_count',\n",
       "       'second_cluster_count', 'EE', 'EI', 'IE', 'II'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72024, 55)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57619, 55)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14405, 55)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 2 ... 3 2 3]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_detour_metrics</th>\n",
       "      <th>mean_POInum</th>\n",
       "      <th>mean_TotalDistance</th>\n",
       "      <th>mean_average_speed</th>\n",
       "      <th>mean_Total_time_interval</th>\n",
       "      <th>EE</th>\n",
       "      <th>EI</th>\n",
       "      <th>IE</th>\n",
       "      <th>II</th>\n",
       "      <th>Average Local</th>\n",
       "      <th>Average Collector</th>\n",
       "      <th>Average Principal Arterial</th>\n",
       "      <th>Average Minor Arterial</th>\n",
       "      <th>Average None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.992155</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>4.749152</td>\n",
       "      <td>0.013728</td>\n",
       "      <td>404.555556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.157407</td>\n",
       "      <td>0.695370</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.119444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.991673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.537133</td>\n",
       "      <td>0.012897</td>\n",
       "      <td>240.375000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.713542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.582224</td>\n",
       "      <td>0.613360</td>\n",
       "      <td>17.355034</td>\n",
       "      <td>0.006699</td>\n",
       "      <td>2105.651269</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.144788</td>\n",
       "      <td>0.205418</td>\n",
       "      <td>0.417828</td>\n",
       "      <td>0.220518</td>\n",
       "      <td>0.011449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.788698</td>\n",
       "      <td>1.915254</td>\n",
       "      <td>25.004719</td>\n",
       "      <td>0.008691</td>\n",
       "      <td>2781.372881</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.184953</td>\n",
       "      <td>0.114037</td>\n",
       "      <td>0.571453</td>\n",
       "      <td>0.105117</td>\n",
       "      <td>0.024441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.973945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.144183</td>\n",
       "      <td>0.014282</td>\n",
       "      <td>396.771930</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.121053</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.582749</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.257602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_detour_metrics  mean_POInum  mean_TotalDistance  mean_average_speed  \\\n",
       "0             0.992155     0.055556            4.749152            0.013728   \n",
       "1             0.991673     0.000000            2.537133            0.012897   \n",
       "2             0.582224     0.613360           17.355034            0.006699   \n",
       "3             0.788698     1.915254           25.004719            0.008691   \n",
       "4             0.973945     0.000000            5.144183            0.014282   \n",
       "\n",
       "   mean_Total_time_interval  EE  EI  IE  II  Average Local  Average Collector  \\\n",
       "0                404.555556   0   0   0   1       0.018519           0.157407   \n",
       "1                240.375000   0   0   0   1       0.083333           0.109375   \n",
       "2               2105.651269   0   0   0   1       0.144788           0.205418   \n",
       "3               2781.372881   0   0   0   1       0.184953           0.114037   \n",
       "4                396.771930   0   0   0   1       0.121053           0.003509   \n",
       "\n",
       "   Average Principal Arterial  Average Minor Arterial  Average None  \n",
       "0                    0.695370                0.009259      0.119444  \n",
       "1                    0.713542                0.000000      0.093750  \n",
       "2                    0.417828                0.220518      0.011449  \n",
       "3                    0.571453                0.105117      0.024441  \n",
       "4                    0.582749                0.035088      0.257602  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed: 62.8min finished\n",
      "C:\\Users\\wangr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\wangr\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "clf = LogisticRegression(random_state=0, max_iter = 1000000)\n",
    "param_grid = {\n",
    "    'penalty': ['l2'],\n",
    "    'C': [3,4,5],\n",
    "    'solver': ['newton-cg', 'sag', 'saga', 'lbfgs'],\n",
    "    'multi_class': ['multinomial']\n",
    "}\n",
    "# Cr\n",
    "grid_search = GridSearchCV(estimator = clf, param_grid = param_grid, scoring='accuracy',\n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "model = LogisticRegression(**best_params)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = metrics.precision_score(y_test, predictions, average = 'micro')\n",
    "precision = metrics.precision_score(y_test, predictions, average = None)\n",
    "recall = metrics.recall_score(y_test, predictions, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 3, 4], dtype=int64), array([19255, 19228, 19136], dtype=int64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 3, 4], dtype=int64), array([4753, 4780, 4872], dtype=int64))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 4, 'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7013536966331135"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89740495, 0.59680639, 0.69718449])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62571008, 0.75062762, 0.72680624])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# clf = SVC(gamma='auto')\n",
    "# param_grid = {'kernel': ['linear'],\n",
    "#                      'C': [1, 10, 100]}\n",
    "                   \n",
    "\n",
    "# grid_search = GridSearchCV(estimator = clf, param_grid = param_grid, scoring='accuracy',\n",
    "#                           cv = 3, n_jobs = -1, verbose = 3)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# best_params = grid_search.best_params_\n",
    "best_params = {'C': 1, 'kernel': 'linear'}\n",
    "model = SVC(**best_params)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = metrics.precision_score(y_test, predictions, average = 'micro')\n",
    "precision = metrics.precision_score(y_test, predictions, average = None)\n",
    "recall = metrics.recall_score(y_test, predictions, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
